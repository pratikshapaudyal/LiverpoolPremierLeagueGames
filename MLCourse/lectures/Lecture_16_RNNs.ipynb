{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks\n",
    "\n",
    "Recurrent neural networks - or RNNs - are built specifically to deal with sequence data. For example, suppose you have a sequence of text of movie reviews and would like to classify their sentiment, or a sequence of stock prices and you would like to predict the next one. These are all tasks well suited for an RNN.\n",
    "\n",
    "To better understand, let's take a look at this blog post:\n",
    "\n",
    "http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "RNN's can take many different forms:\n",
    "\n",
    "* Sequence of inputs to sequence of outputs\n",
    "* Sequence of inputs to vector of output\n",
    "* Vector of input to sequence of outps\n",
    "* Encoder -> Decoder\n",
    "\n",
    "We can take a closer look on p. 384 of Hands on Machine Learning\n",
    "\n",
    "## Variable length sequences\n",
    "\n",
    "If you have variable length inputs, like movie reviews which differ in length. A decent technique is to pick a fairly large input sequence length and zero padd all the inputs which are smaller. See here:\n",
    "\n",
    "https://github.com/keras-team/keras/issues/40\n",
    "\n",
    "If you have variable length output sequences - for example, when generating text. You can define a special end of sequence tag such as <EOS> and ignore any output past that tag.\n",
    "\n",
    "\n",
    "## Issues with RNNs:\n",
    "\n",
    "* Vanishing/Exploding gradients\n",
    "* Take a long time to train\n",
    "* Memory of first inputs tends to fad away making their long-term memory weak\n",
    "\n",
    "## LSTM\n",
    "\n",
    "* Much more capable of learning long-term dependencies\n",
    "* Same structure as vanilla RNN, but has 4 neural networks inside\n",
    "* Has two states which are passed to the next part of the sequence\n",
    "* The first state is the **cell state** and only has small changes made to it and thus it is very easy for information to be passed forward.\n",
    "* The first change we can make to the cell state is remove information from it. This is done with a **forget gate.** The forget gate is a fully connected neural net where the input is the concat of previous hidden state (not the cell state) and the sequence input. It is activated with a sigmoid and thus gives values from zero to one. A 1 means keep all the information.\n",
    "* The second change we make to the cell state is decide which information should be added. To do this, we take the combined hidden and input and feed it through another fully connected layer activated by a sigmoid - this is the **input gate.** We also take this combined input and feed it through what I will call the **tanh gate.** This gate is a fully connected layer activated by a tanh function - like sigmoid but ranges from -1 to 1. We then combine these two gates output with pointwise multiplication - basically the input gate tells how much information to keep from the tanh gate.\n",
    "* Now that we have our forget and remember values we will take the incoming cell state and multiply it by the forget values and add in the remember values.\n",
    "* Lastly, we need to decide what to output which will also be our hidden state we carry forward.\n",
    "* First, we take the combined input and hidden state through what I will call the **output gate.** This is a fully connected layer activated by a sigmoid.\n",
    "* Then, we take the updated cell value and pass it through a tanh to force its values to range from -1 to 1 and multiply these values by the output gate - the output gate telling us what to keep.\n",
    "* We carry this value forward as the hidden state and pass it through a softmax and a final fully connected layer to get our output.\n",
    "\n",
    "## GRU\n",
    "\n",
    "GRU is basically a simplified version of an LSTM that seems to perform just as well for most tasks and thus has been growing in popularity. To learn more about it take a look at the blog post or p. 406 of Hands on Machine learning.\n",
    "\n",
    "There are also many other RNN architectures that we don't metion here.\n",
    "\n",
    "## Word Embeddings\n",
    "\n",
    "A very interesting challenge in NLP is: how do we represent the meaning of a word to a computer? One idea might be to reprsent words as a sparse vector the size of your vocabulary where each vector is all zeros except for a one at the appropriate index for that word. This has some pretty obvious drawbacks. One, it is very large. Two, is it really has no notion of how words are similar in their meanings.\n",
    "\n",
    "One way we have solved some portion of these problems is by learning dense word embeddings. These embeddings - or vectors - should encode the meaning of a word sufficiently enough that we can hopefully compare vectors.\n",
    "\n",
    "A technique to do this - there are many - is called **Continuous Bag-of-Words (CBOW)**. Also, referred to as word2vec, though, there is another flavor of word2vec. The idea is to use the context of a word as features to predict the target word.\n",
    "\n",
    "What is the context? Simple - the words surrounding the target word. Usually, around +-2 words. You then define how big of a dimension you want for your embeddings - say 128.\n",
    "\n",
    "Then, you train a neural network to find the best 128 dimension embeddings using the context words to predict the target word.\n",
    "\n",
    "Note: an embedding is just a fancy name for a look-up table. An embedding takes in an index (for example, 1) and returns the vector it finds at that index, which in our example would be of size 128. The embedding table should have the same number of rows as vocabulary words.\n",
    "\n",
    "And like anything involving gradient descent, our embeddings will basically start off with random numbers and we will use gradient descent to optimize them given our training data.\n",
    "\n",
    "Let's see some code motiviated by the following (also see p.407 of hands on machine learning):\n",
    "\n",
    "http://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html\n",
    "\n",
    "https://github.com/FraLotito/continuous-bag-of-words\n",
    "\n",
    "## CBOW Pytorch Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict\n",
    "import torch.distributions as distributions\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(tweets):\n",
    "    data = []\n",
    "    for tweet in tweets:\n",
    "        tokens = tweet.split(\" \")\n",
    "        for i in range(2, len(tokens) - 2):\n",
    "            context = [tokens[i - 2], tokens[i - 1],\n",
    "                       tokens[i + 1], tokens[i + 2]]\n",
    "            target = tokens[i]\n",
    "            data.append((context, target))\n",
    "    return data\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tfolkman/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:1: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'And so the robots spared humanity ... https://t.co/v7JUJQWfCv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_csv(\"../small_data/elonmusk_tweets.csv\")\n",
    "tweets = df.text.values\n",
    "tweets = [t[2:-1] for t in tweets]\n",
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['And', 'so', 'robots', 'spared'], 'the'),\n",
       " (['so', 'the', 'spared', 'humanity'], 'robots'),\n",
       " (['the', 'robots', 'humanity', '...'], 'spared')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = make_data(tweets)\n",
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30603"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1216\n"
     ]
    }
   ],
   "source": [
    "words = [w for t in tweets for w in t.split()]\n",
    "common_words = [w for w,c in Counter(words).most_common() if c >=5]\n",
    "vocab = set(common_words)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "print(len(common_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_index(word):\n",
    "    if word in word_to_ix:\n",
    "        return word_to_ix[word]\n",
    "    else:\n",
    "        return len(word_to_ix)\n",
    "    \n",
    "def make_context_vector(context, get_word_index):\n",
    "    idxs = [get_word_index(w) for w in context]\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    return Variable(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(CBOW, self).__init__()\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.log_softmax = nn.LogSoftmax()\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        ## view changes the size to be one row\n",
    "        embeds = sum(self.embeddings(inputs)).view(1,-1)\n",
    "        out = self.linear1(embeds)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.log_softmax(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "    def get_word_emdedding(self, word):\n",
    "        word = Variable(torch.LongTensor([word_to_ix[word]]))\n",
    "        return self.embeddings(word).view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow = CBOW(len(vocab)+1, 100, 128)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(cbow.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cbow(context, target):\n",
    "    context_vector = make_context_vector(context, get_word_index)  \n",
    "    cbow.zero_grad()\n",
    "    log_probs = cbow(context_vector)\n",
    "    loss = criterion(log_probs, Variable(\n",
    "        torch.LongTensor([get_word_index(target)])))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tfolkman/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 0s (0 0%) 8.0488\n",
      "0m 5s (5000 3%) 2.6982\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-668809089697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_cbow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-8ef9b9116f09>\u001b[0m in \u001b[0;36mtrain_cbow\u001b[0;34m(context, target)\u001b[0m\n\u001b[1;32m      5\u001b[0m     loss = criterion(log_probs, Variable(\n\u001b[1;32m      6\u001b[0m         torch.LongTensor([get_word_index(target)])))\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tfolkman/anaconda3/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tfolkman/anaconda3/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "print_every = 5000\n",
    "plot_every = 500\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "iter = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    for context, target in data:\n",
    "        loss = train_cbow(context, target)\n",
    "        total_loss += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / (len(data) * n_epochs) * 100, loss))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            all_losses.append(total_loss / plot_every)\n",
    "            total_loss = 0\n",
    "        \n",
    "        iter = iter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAFfCAYAAAArnzSxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(all_losses)\n",
    "plt.ylim(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(w1, w2, model):\n",
    "    e1 = model.get_word_emdedding(w1)\n",
    "    e2 = model.get_word_emdedding(w2)\n",
    "    return (e1.dot(e2) / (torch.norm(e1) * torch.norm(e2))).data.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(e1, e2):\n",
    "    return (e1.dot(e2) / (torch.norm(e1) * torch.norm(e2))).data.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similar(w1, model, n=5):\n",
    "    words = []\n",
    "    similarities = []\n",
    "    for w, i in word_to_ix.items():\n",
    "        if w == w1:\n",
    "            continue\n",
    "        similarity = get_similarity(w1, w, model)\n",
    "        words.append(w)\n",
    "        similarities.append(similarity)\n",
    "    srtd_similarities, srtd_words = (list(x) for x in zip(*sorted(zip(similarities, words), reverse=True)))\n",
    "    return srtd_words[:n], srtd_similarities[:n]\n",
    "\n",
    "def get_most_similar_2(w1, model, n=5):\n",
    "    words = []\n",
    "    similarities = []\n",
    "    for w, i in word_to_ix.items():\n",
    "        similarity = cosine_distance(w1, model.get_word_emdedding(w))\n",
    "        words.append(w)\n",
    "        similarities.append(similarity)\n",
    "    srtd_similarities, srtd_words = (list(x) for x in zip(*sorted(zip(similarities, words), reverse=True)))\n",
    "    return srtd_words[:n], srtd_similarities[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected argument self to have 1 dimension, but has 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0bf2f202e66d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_most_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Falcon'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-f205c634d45f>\u001b[0m in \u001b[0;36mget_most_similar\u001b[0;34m(w1, model, n)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-9ccdcbe9aeea>\u001b[0m in \u001b[0;36mget_similarity\u001b[0;34m(w1, w2, model)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0me1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word_emdedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0me2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word_emdedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected argument self to have 1 dimension, but has 2"
     ]
    }
   ],
   "source": [
    "get_most_similar('Falcon', cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected argument self to have 1 dimension, but has 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-2f8bd3999303>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0malgebra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word_emdedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mars'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcbow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word_emdedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Earth\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcbow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word_emdedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Falcon\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_most_similar_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgebra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-f205c634d45f>\u001b[0m in \u001b[0;36mget_most_similar_2\u001b[0;34m(w1, model, n)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word_emdedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-5a5fd0513c34>\u001b[0m in \u001b[0;36mcosine_distance\u001b[0;34m(e1, e2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcosine_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected argument self to have 1 dimension, but has 2"
     ]
    }
   ],
   "source": [
    "algebra = cbow.get_word_emdedding('Mars') - cbow.get_word_emdedding(\"Earth\") + cbow.get_word_emdedding(\"Falcon\")\n",
    "get_most_similar_2(algebra, cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder-Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of RNN and LSTM using pytorch\n",
    "\n",
    "Source: http://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html#sphx-glr-intermediate-char-rnn-generation-tutorial-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_names = []\n",
    "name_weights = []\n",
    "for year in range(2000,2017):\n",
    "    with open(\"../small_data/baby_names/yob{}.txt\".format(year), \"r\") as f:\n",
    "        for line in f:\n",
    "            columns = line.split(\",\")\n",
    "            if columns[1] == 'F':\n",
    "                female_names.append(columns[0])\n",
    "                name_weights.append(int(columns[2].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Emily', 'Hannah', 'Madison', 'Ashley', 'Sarah']"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326418\n"
     ]
    }
   ],
   "source": [
    "n_names = len(female_names)\n",
    "print(n_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25953, 23078, 19967, 17996, 17691]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_weights[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_names_weights = defaultdict(int)\n",
    "for i in range(n_names):\n",
    "    name = female_names[i]\n",
    "    weight = name_weights[i]\n",
    "    unique_names_weights[name] = unique_names_weights[name] + weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_names = list(unique_names_weights.keys())\n",
    "unique_weights = list(unique_names_weights.values())\n",
    "unique_probabilities = np.array(unique_weights) / sum(unique_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input_combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(1, self.hidden_size))\n",
    "    \n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.forget_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.input_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.tanh_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.output_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        self.result_gate = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input_combined = torch.cat((input, hidden), 1)\n",
    "        \n",
    "        forget_gate_value = self.sigmoid(self.forget_gate(input_combined))\n",
    "        input_gate_value = self.sigmoid(self.input_gate(input_combined))\n",
    "        tanh_gate_value = self.tanh(self.tanh_gate(input_combined))\n",
    "        output_gate_value = self.sigmoid(self.output_gate(input_combined))\n",
    "        \n",
    "        input_tanh_combined = input_gate_value * tanh_gate_value\n",
    "        \n",
    "        cell_next = cell * forget_gate_value + input_tanh_combined\n",
    "        hidden_next = self.tanh(cell_next) * output_gate_value\n",
    "        output = self.result_gate(hidden_next)\n",
    "\n",
    "        return output, hidden_next, cell_next\n",
    "\n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = set([c.lower() for name in female_names for c in name])\n",
    "letters_to_index = {l:i for i,l in enumerate(letters)}\n",
    "index_to_letter = {i:l for l, i in letters_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_letters = len(letters) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li in range(len(line)):\n",
    "        letter = line[li].lower()\n",
    "        tensor[li][0][letters_to_index[letter]] = 1\n",
    "    return tensor\n",
    "\n",
    "def targetTensor(line):\n",
    "    letter_indexes = [letters_to_index[line[li].lower()] for li in range(1, len(line))]\n",
    "    letter_indexes.append(n_letters - 1) # EOS\n",
    "    return torch.LongTensor(letter_indexes)\n",
    "\n",
    "def randomTrainingPair():\n",
    "    return np.random.choice(unique_names, p=unique_probabilities, size=1)[0]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    line = randomTrainingPair()\n",
    "    input_line_tensor = Variable(inputTensor(line))\n",
    "    target_line_tensor = Variable(targetTensor(line))\n",
    "    return input_line_tensor, target_line_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lstm = LSTM(n_letters, 128, n_letters)\n",
    "\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=.001)\n",
    "\n",
    "def train(input_line_tensor, target_line_tensor):\n",
    "    hidden = lstm.initHidden()\n",
    "    cell = lstm.initHidden()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "    for i in range(input_line_tensor.size()[0]):\n",
    "        output, hidden, cell = lstm(input_line_tensor[i], hidden, cell)\n",
    "        loss += criterion(output, target_line_tensor[i].unsqueeze(0))\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return output, loss.data[0] / input_line_tensor.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tfolkman/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:21: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 37s (5000 25%) 2.5280\n",
      "3m 30s (10000 50%) 1.7749\n",
      "5m 28s (15000 75%) 1.7115\n",
      "7m 9s (20000 100%) 1.8437\n"
     ]
    }
   ],
   "source": [
    "n_iters = 20000\n",
    "print_every = 5000\n",
    "plot_every = 500\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    input_t, target_t = randomTrainingExample()\n",
    "    output, loss = train(input_t, target_t)\n",
    "    total_loss += loss\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11fae16a0>]"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAFdCAYAAABmV5W6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRQFBRERESlFAEBERkVIUEERERKSU/w9qIiYkF0BscgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 20\n",
    "\n",
    "# Sample from a category and starting letter\n",
    "def sample(start_letter='A'):\n",
    "    input = Variable(inputTensor(start_letter))\n",
    "    hidden = lstm.initHidden()\n",
    "    cell = lstm.initHidden()\n",
    "\n",
    "    output_name = start_letter\n",
    "\n",
    "    for i in range(max_length):\n",
    "        output, hidden, cell = lstm(input[0], hidden, cell)\n",
    "        sm = nn.Softmax(dim=1)\n",
    "        softmax_out = sm(Variable(output.data)).data.numpy()[0]\n",
    "        topi = np.random.choice(range(len(softmax_out)), p=softmax_out)\n",
    "        if topi == n_letters - 1:\n",
    "            break\n",
    "        else:\n",
    "            letter = index_to_letter[topi]\n",
    "            output_name += letter\n",
    "        input = Variable(inputTensor(letter))\n",
    "\n",
    "    return output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cilly'"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample('c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
